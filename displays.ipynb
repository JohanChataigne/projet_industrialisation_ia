{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_section'></a>\n",
    "# Data section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section adds some informations about the datas used to train and test the model. It is important to know well the dataset if we want to explain the current model's behavior and improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (6035, 2)\n",
      "Test shape : (1065, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load training and test sets\n",
    "\n",
    "df_train = pd.read_json('datas/training_set.json')\n",
    "df_test = pd.read_json('datas/testing_set.json')\n",
    "\n",
    "print(f\"Train shape : {df_train.shape}\")\n",
    "print(f\"Test shape : {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations and visualisations of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6035</td>\n",
       "      <td>6035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8</td>\n",
       "      <td>6035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>Je voudrais que tu me dises si le dernier Mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            intent                                           sentence\n",
       "count         6035                                               6035\n",
       "unique           8                                               6035\n",
       "top     irrelevant  Je voudrais que tu me dises si le dernier Mari...\n",
       "freq          3852                                                  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stats on the training set\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "We see here there is indeed a total of 8 dfferent intents.\n",
    "Moreover, the *irrelevant* intent in highly represented in the dataset (3852/6035).  \n",
    "\n",
    "This can be good since *irrelevant* is the intent for every sentence that doesn't fit one of the 7 others. It is less specific than the others so it may need more examples to be well-recognized. Nevertheless, it can involve weak detections for the other intents by the model, because of a too small amount of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6035 entries, 0 to 6034\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   intent    6035 non-null   object\n",
      " 1   sentence  6035 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 94.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Informations about colums\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "The dataset is made of 2 columns:\n",
    "- `intent` is our target\n",
    "- `sentence` is the input, it's what the user will give to the model\n",
    "\n",
    "Both columns are categorical, we have no numerical value here.\n",
    "In addition, there isn't any missing value (*non-null*).  \n",
    "To finish, an important preprocessing part is needed before feeding a model with the datas since it is text (*i.e.* Tokenization, Feature extraction, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>850€ maximum pour le loyer, à partir de janvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>D'imprimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purchase</td>\n",
       "      <td>Le meilleur cabriolet hybrid moins de 5m10 min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find-hotel</td>\n",
       "      <td>en ce moment je cher un location pour les vaca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>c'est possible de t'utiliser la nuit ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>J'ai besoin d'acheter un fusil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>Vous pouvez réserver pour 09h oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>Du 20 au 22 novembre pour 100-150 euros la nuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>purchase</td>\n",
       "      <td>Mon docteur m'a suggéré de porter des bandes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>purchase</td>\n",
       "      <td>Commande à effectuer : 30 bloc note petits car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intent                                           sentence\n",
       "0  irrelevant  850€ maximum pour le loyer, à partir de janvie...\n",
       "1  irrelevant                                         D'imprimer\n",
       "2    purchase  Le meilleur cabriolet hybrid moins de 5m10 min...\n",
       "3  find-hotel  en ce moment je cher un location pour les vaca...\n",
       "4  irrelevant             c'est possible de t'utiliser la nuit ?\n",
       "5  irrelevant                     J'ai besoin d'acheter un fusil\n",
       "6  irrelevant                  Vous pouvez réserver pour 09h oui\n",
       "7  irrelevant    Du 20 au 22 novembre pour 100-150 euros la nuit\n",
       "8    purchase  Mon docteur m'a suggéré de porter des bandes p...\n",
       "9    purchase  Commande à effectuer : 30 bloc note petits car..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 10 first elements\n",
    "df_train.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "<p>This gives us some examples of rows in the dataset. We notice there are both short and long sentences, well-written or not, which is good to train the model on various writting styles (to work well on the different users' styles in production).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "irrelevant           3852\n",
       "purchase              613\n",
       "find-restaurant       469\n",
       "find-around-me        383\n",
       "find-hotel            316\n",
       "find-train            143\n",
       "find-flight           142\n",
       "provide-showtimes     117\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 8 different intents rows counts\n",
    "df_train[\"intent\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "irrelevant           63.83\n",
       "purchase             10.16\n",
       "find-restaurant       7.77\n",
       "find-around-me        6.35\n",
       "find-hotel            5.24\n",
       "find-train            2.37\n",
       "find-flight           2.35\n",
       "provide-showtimes     1.94\n",
       "Name: intent, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratios (%) for each intent\n",
    "total = df_train.shape[0]\n",
    "round(df_train['intent'].value_counts() / total * 100 , 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "We get here a more detailed count of rows for each intent. As we said before, there are mostly *irrelevant* rows (63%), the dataset is really unbalanced. There will be some analysis to make about the measures used to evaluate any model trained on this dataset.  \n",
    "\n",
    "It's also unbalanced between the 7 'specific' intents. Maybe that's due to the use of the app made by the clients, asking more often for purchase matters than for showtimes ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only informations we have about the model are the measures given in the base project's README file. <br>\n",
    "As the main problem is that we don't know how they were computed (which datas, cross-validation or not, etc..), we will try in the following cells to get our own measures on the datas we were given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch application to have access to the model\n",
    "# Don't forget to pull image before doing anything else : docker pull wiidiiremi/projet_industrialisation_ia_3a\n",
    "# This may take some time\n",
    "\n",
    "# Change your custom port here\n",
    "port = '8080'\n",
    "os.system('docker run -p 8080:' + port + ' 3eec8ccf7aec &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the model\n",
    "The goal of the model is to find among the 8 intents which one fits to the most the user's request (*i.e.* sentence).\n",
    "As a consequence, it is a **classification problem with 8 classes**.  \n",
    "We can confirm the model is a classifier with the 8 probabilities he returns (*json* response) when given a sentence.  \n",
    "However, we can't know what it is made of. It could be either a Neural Network or a Softmax Regression for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split datasets in inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = df_train['sentence']\n",
    "df_y_train = df_train['intent']\n",
    "df_x_test = df_test['sentence']\n",
    "df_y_test = df_test['intent']\n",
    "\n",
    "print(f\"Train data shape : {df_x_train.shape}\")\n",
    "print(f\"Train labels shape : {df_y_train.shape}\")\n",
    "print(f\"Test data shape : {df_x_test.shape}\")\n",
    "print(f\"Test labels shape : {df_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model predictions for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the 8080 is you custom port from docker run command\n",
    "route = 'http://localhost:' + port + '/api/intent?'\n",
    "\n",
    "# Function to get the model's predictions for a given dataset\n",
    "def predict(datas):\n",
    "    \n",
    "    # List of predicted intents\n",
    "    predicted_labels = []\n",
    "    # List of probabilities for the predicted intents\n",
    "    prediction_probabilities = []\n",
    "    \n",
    "    # Request the model for each data\n",
    "    for data in datas:\n",
    "        \n",
    "        try:\n",
    "            res = rq.get(route, {'sentence':data}).json()\n",
    "        except:\n",
    "            print(\"Request Error: Service not available\")\n",
    "            return predicted_labels, prediction_probabilities \n",
    "        \n",
    "        predicted_class = max(res, key=res.get)\n",
    "        predicted_values = list(res.values())\n",
    " \n",
    "        predicted_labels.append(predicted_class)\n",
    "        prediction_probabilities.append(predicted_values)\n",
    "        \n",
    "    return predicted_labels, prediction_probabilities   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get both datasets predictions from the model\n",
    "train_predicted_labels, train_predicted_probabilities = predict(df_x_train)\n",
    "test_predicted_labels, test_predicted_probabilities = predict(df_x_test)\n",
    "\n",
    "assert len(train_predicted_labels) == df_x_train.shape[0]\n",
    "assert len(train_predicted_labels) == df_x_train.shape[0]\n",
    "assert len(test_predicted_labels) == df_x_test.shape[0]\n",
    "assert len(test_predicted_labels) == df_x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute model's various scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(df_y_train, train_predicted_labels)\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training scores\n",
    "print(classification_report(df_y_train, train_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scores\n",
    "print(classification_report(df_y_test, test_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all intents in the same order as the model's output\n",
    "intents = [\"find-train\", \"irrelevant\", \"find-flight\", \"find-restaurant\", \"purchase\", \"find-around-me\", \"provide-showtimes\", \"find-hotel\"]\n",
    "\n",
    "# Function mapping a true label to a probabilities array \n",
    "def labelToProbs(label):\n",
    "    \n",
    "    assert label in intents\n",
    "    \n",
    "    # All probabilities are 0\n",
    "    probs = np.zeros(8)\n",
    "    \n",
    "    for index, intent in enumerate(intents):\n",
    "        if label == intent:\n",
    "            # Set true label porbability to 1\n",
    "            probs[index] = 1\n",
    "            return probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC scores\n",
    "\n",
    "# Map True labels to probabilties arrays in order to compute ROC score\n",
    "mapping = lambda x: labelToProbs(x)\n",
    "\n",
    "y_true_train = list(map(mapping, df_y_train.to_numpy()))\n",
    "y_true_test = list(map(mapping, df_y_test.to_numpy()))\n",
    "\n",
    "train_roc = roc_auc_score(y_true_train, train_predicted_probabilities, multi_class='ovo')\n",
    "test_roc = roc_auc_score(y_true_test, test_predicted_probabilities, multi_class='ovo')\n",
    "\n",
    "print(f\"Training ROC AUC : {round(train_roc,3)}\")\n",
    "print(f\"Test ROC AUC : {round(test_roc, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "The classification reports show an accuracy of **81%** for training (**80%** for test). We could say it is not that bad for a first model.\n",
    "However, as we saw in the [Data Section](#data_section) that our dataset is unbalanced (64:36 ratio between *irrelevant* class and the seven others). As a conclusion, we can't rate our model with its accuracy since it will tend to choose *irrelevant* to have the best accuracy ([see 'Accuracy Paradox'](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments about the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments about hte performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments about the documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
