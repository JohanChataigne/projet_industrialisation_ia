{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (6035, 2)\n",
      "Test shape : (1065, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load training and test sets\n",
    "\n",
    "df_train = pd.read_json('datas/training_set.json')\n",
    "df_test = pd.read_json('datas/testing_set.json')\n",
    "\n",
    "print(f\"Train shape : {df_train.shape}\")\n",
    "print(f\"Test shape : {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations and visualisations of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6035</td>\n",
       "      <td>6035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8</td>\n",
       "      <td>6035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>Peux tu me dire combien coûterait un bac en bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            intent                                           sentence\n",
       "count         6035                                               6035\n",
       "unique           8                                               6035\n",
       "top     irrelevant  Peux tu me dire combien coûterait un bac en bo...\n",
       "freq          3852                                                  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stats on the training set\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "We see here there is indeed a total of 8 dfferent intents.\n",
    "Moreover, the *irrelevant* intent in highly represented in the dataset (3852/6035).\n",
    "\n",
    "This can be good since *irrelevant* is the intent for every sentence that doesn't fit one of the 7 others. It is less specific than the others so it may need more examples to be well-recognized. Nevertheless, it can involve weak detections for the other intents by the model, because of a too small amount of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6035 entries, 0 to 6034\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   intent    6035 non-null   object\n",
      " 1   sentence  6035 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 94.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Informations about colums\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "The dataset is made of 2 columns:\n",
    "- `intent` is our target\n",
    "- `sentence` is the input, it's what the user will give to the model\n",
    "\n",
    "Both columns are categorical, we have no numerical values here.\n",
    "In addition, there aren't any missing values (*non-null*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>850€ maximum pour le loyer, à partir de janvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>D'imprimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purchase</td>\n",
       "      <td>Le meilleur cabriolet hybrid moins de 5m10 min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find-hotel</td>\n",
       "      <td>en ce moment je cher un location pour les vaca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>c'est possible de t'utiliser la nuit ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>J'ai besoin d'acheter un fusil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>Vous pouvez réserver pour 09h oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>Du 20 au 22 novembre pour 100-150 euros la nuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>purchase</td>\n",
       "      <td>Mon docteur m'a suggéré de porter des bandes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>purchase</td>\n",
       "      <td>Commande à effectuer : 30 bloc note petits car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intent                                           sentence\n",
       "0  irrelevant  850€ maximum pour le loyer, à partir de janvie...\n",
       "1  irrelevant                                         D'imprimer\n",
       "2    purchase  Le meilleur cabriolet hybrid moins de 5m10 min...\n",
       "3  find-hotel  en ce moment je cher un location pour les vaca...\n",
       "4  irrelevant             c'est possible de t'utiliser la nuit ?\n",
       "5  irrelevant                     J'ai besoin d'acheter un fusil\n",
       "6  irrelevant                  Vous pouvez réserver pour 09h oui\n",
       "7  irrelevant    Du 20 au 22 novembre pour 100-150 euros la nuit\n",
       "8    purchase  Mon docteur m'a suggéré de porter des bandes p...\n",
       "9    purchase  Commande à effectuer : 30 bloc note petits car..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 10 first elements\n",
    "df_train.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "This gives us some examples of rows in the dataset. We notice there are both short and long sentences, well-written or not, which is good to train the model on various writting styles (to work well on the different users' styles in production)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "irrelevant           3852\n",
       "purchase              613\n",
       "find-restaurant       469\n",
       "find-around-me        383\n",
       "find-hotel            316\n",
       "find-train            143\n",
       "find-flight           142\n",
       "provide-showtimes     117\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 8 different intents\n",
    "df_train[\"intent\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "We get here a more detailed count of rows for each intent. As we said before, there are mostly *irrelevant* rows (but maybe for a good reason). \n",
    "\n",
    "Ohterwize, it's also kind of unbalanced between the 7 'specific' intents. It would have been nice to have an explonation for that. Maybe it's due to the use of the app made by the clients, asking more often for purchase matters than for showtimes ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch application to have access to the model\n",
    "# This may take some time\n",
    "os.system('docker run -p 8080:8080 3eec8ccf7aec &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split datasets in inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape : (6035,)\n",
      "Train labels shape : (6035,)\n",
      "Test data shape : (1065,)\n",
      "Test labels shape : (1065,)\n"
     ]
    }
   ],
   "source": [
    "df_x_train = df_train['sentence']\n",
    "df_y_train = df_train['intent']\n",
    "df_x_test = df_test['sentence']\n",
    "df_y_test = df_test['intent']\n",
    "\n",
    "print(f\"Train data shape : {df_x_train.shape}\")\n",
    "print(f\"Train labels shape : {df_y_train.shape}\")\n",
    "print(f\"Test data shape : {df_x_test.shape}\")\n",
    "print(f\"Test labels shape : {df_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model predictions for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = 'http://localhost:8080/api/intent?'\n",
    "\n",
    "# Function to get the model's predictions for a given dataset\n",
    "def predict(datas):\n",
    "    \n",
    "    # List of predicted intents\n",
    "    predicted_labels = []\n",
    "    # List of probabilities for the predicted intents\n",
    "    prediction_probabilities = []\n",
    "    \n",
    "    # Request the model for each data\n",
    "    for data in datas:\n",
    "        \n",
    "        try:\n",
    "            res = rq.get(route, {'sentence':data}).json()\n",
    "        except:\n",
    "            print(\"Request Error: Service not available\")\n",
    "            return [], []\n",
    "        \n",
    "        predicted_class = max(res, key=res.get)\n",
    "        predicted_value = max(res.values())\n",
    " \n",
    "        predicted_labels.append(predicted_class)\n",
    "        prediction_probabilities.append(predicted_value)\n",
    "        \n",
    "    return predicted_labels, prediction_probabilities   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service not available\n",
      "Service not available\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2850b380f0f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_predicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predicted_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_x_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_x_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_x_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_x_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get both datasets predictions from the model\n",
    "train_predicted_labels, train_predicted_probabilities = predict(df_x_train)\n",
    "test_predicted_labels, test_predicted_probabilities = predict(df_x_test)\n",
    "\n",
    "assert len(train_predicted_labels) == df_x_train.shape[0]\n",
    "assert len(train_predicted_labels) == df_x_train.shape[0]\n",
    "assert len(test_predicted_labels) == df_x_test.shape[0]\n",
    "assert len(test_predicted_labels) == df_x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute model's various scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training scores\n",
    "print(classification_report(df_y_train, train_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scores\n",
    "print(classification_report(df_y_test, test_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
