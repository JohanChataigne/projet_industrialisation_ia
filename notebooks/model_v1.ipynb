{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from preprocessing.preprocessing import Preprocessor\n",
    "from preprocessing.dataset_balancing import Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, Input\n",
    "from tensorflow.keras.metrics import Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (6035, 2)\n",
      "Test shape : (1065, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load training and test sets\n",
    "df_train = pd.read_json('../datas/training_set.json')\n",
    "df_test = pd.read_json('../datas/testing_set.json')\n",
    "\n",
    "print(f\"Train shape : {df_train.shape}\")\n",
    "print(f\"Test shape : {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the train set\n",
    "train_balance = Balance(df_train)\n",
    "train_balance.process_balance('../preprocessed_data/train_balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\preprocessing\\preprocessing.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  data = np.array(data)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "train_preprocessor = Preprocessor(train_balance.df_dataset)\n",
    "train_preprocessor.preprocess('../preprocessed_data/train_nlp_preprocessed')\n",
    "test_preprocessor = Preprocessor(df_test)\n",
    "test_preprocessor.preprocess('../preprocessed_data/test_nlp_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.9918094, -2.0211177, -3.1467276, -0.7597667...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.37102285, -0.25975516, -2.5644374, 1.239701...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.5238122, -1.4262346, -0.8189889, 0.9439444,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2.6711895, -3.8386414, -3.3684235, 0.06278875...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.16812666, -1.4507266, -3.699288, -0.9399957...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  [1.9918094, -2.0211177, -3.1467276, -0.7597667...   \n",
       "1  [0.37102285, -0.25975516, -2.5644374, 1.239701...   \n",
       "2  [0.5238122, -1.4262346, -0.8189889, 0.9439444,...   \n",
       "3  [2.6711895, -3.8386414, -3.3684235, 0.06278875...   \n",
       "4  [0.16812666, -1.4507266, -3.699288, -0.9399957...   \n",
       "\n",
       "                                     intent  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessor.df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (15996, 300)\n",
      "y_train.shape =  (15996, 8)\n",
      "x_test.shape =  (1065, 300)\n",
      "y_test.shape =  (1065, 8)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(list(train_preprocessor.df_dataset['sentence']))\n",
    "y_train = np.array(list(train_preprocessor.df_dataset['intent']))\n",
    "x_test = np.array(list(test_preprocessor.df_dataset['sentence']))\n",
    "y_test = np.array(list(test_preprocessor.df_dataset['intent']))\n",
    "\n",
    "print(\"x_train.shape = \", x_train.shape)\n",
    "print(\"y_train.shape = \", y_train.shape)\n",
    "print(\"x_test.shape = \", x_test.shape)\n",
    "print(\"y_test.shape = \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (15996, 1, 300)\n",
      "x_test.shape =  (1065, 1, 300)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print(\"x_train.shape = \", x_train.shape)\n",
    "print(\"x_test.shape = \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 128)               186880    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 199,816\n",
      "Trainable params: 199,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(64), input_shape=x_train[0].shape))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 5s 4ms/step - loss: 1.8913 - precision: 0.5117\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.8707 - precision: 0.8469\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.5615 - precision: 0.8889\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.4220 - precision: 0.9142\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.3416 - precision: 0.9285\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.2695 - precision: 0.9424\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.2171 - precision: 0.9558\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1907 - precision: 0.9613\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1665 - precision: 0.9641\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1430 - precision: 0.9720\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1229 - precision: 0.9730\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1189 - precision: 0.9750\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1111 - precision: 0.9756\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0994 - precision: 0.9772\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0914 - precision: 0.9788\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0710 - precision: 0.9843\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0731 - precision: 0.9832\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0759 - precision: 0.9822\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0761 - precision: 0.9832\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0583 - precision: 0.9861\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=[Precision()]\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/model_v1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 1ms/step - loss: 1.1690 - precision: 0.8145\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 1.1689561605453491\n",
      "Test precision = 0.8145315647125244\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss =\", score[0])\n",
    "print(\"Test precision =\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1065, 8)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065\n",
      "1065\n"
     ]
    }
   ],
   "source": [
    "y_test_true = list(map(lambda x: np.argmax(x), y_test))\n",
    "y_test_pred = list(map(lambda x: np.argmax(x), y_pred))\n",
    "print(len(y_test_true))\n",
    "print(len(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 4, 3, 1, 0, 1, 1, 1]\n",
      "[4, 1, 1, 4, 3, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_true[:10])\n",
    "print(y_test_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8263126529465825\n"
     ]
    }
   ],
   "source": [
    "fbeta = fbeta_score(y_test_true, y_test_pred, beta=0.5, labels=list(range(8)), average='weighted')\n",
    "print(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77        21\n",
      "           1       0.93      0.82      0.87       677\n",
      "           2       0.84      0.88      0.86        24\n",
      "           3       0.75      0.85      0.79        93\n",
      "           4       0.64      0.84      0.72       114\n",
      "           5       0.62      0.61      0.62        67\n",
      "           6       0.64      1.00      0.78        14\n",
      "           7       0.56      0.78      0.65        55\n",
      "\n",
      "    accuracy                           0.81      1065\n",
      "   macro avg       0.71      0.83      0.76      1065\n",
      "weighted avg       0.83      0.81      0.82      1065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training scores\n",
    "print(classification_report(y_test_true, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
